{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27a1889",
   "metadata": {},
   "source": [
    "# Benchmarking Classical vs Genetic Neural Networks\n",
    "\n",
    "This notebook benchmarks classical feed-forward fully connected neural networks against networks using GeneticLayer on several classification datasets from scikit-learn, including complex ones like Olivetti faces and forest cover types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43e78a",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8587552",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421c09a",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e0f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.datasets import (\n",
    "    fetch_covtype,\n",
    "    fetch_olivetti_faces,\n",
    "    load_breast_cancer,\n",
    "    load_digits,\n",
    "    load_iris,\n",
    "    load_wine,\n",
    "    make_classification,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from examples.utils.network_factory import (\n",
    "    create_feedforward_classical_network,\n",
    "    create_feedforward_genetic_network,\n",
    "    create_heads_classical_network,\n",
    "    create_heads_genetic_network,\n",
    ")\n",
    "from examples.utils.plotting_utils import (\n",
    "    plot_architecture_comparison,\n",
    "    plot_bal_acc_vs_params,\n",
    ")\n",
    "from examples.utils.trainer_utils import train_and_evaluate\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c6c84",
   "metadata": {},
   "source": [
    "### 1.2 Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess datasets\n",
    "datasets = {\n",
    "    \"digits\": load_digits(),\n",
    "    \"iris\": load_iris(),\n",
    "    \"wine\": load_wine(),\n",
    "    \"breast_cancer\": load_breast_cancer(),\n",
    "    \"synthetic\": make_classification(\n",
    "        n_samples=1500,\n",
    "        n_features=50,\n",
    "        n_informative=30,\n",
    "        n_redundant=10,\n",
    "        n_classes=7,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"covtype\": fetch_covtype(),\n",
    "    \"olivetti\": fetch_olivetti_faces(),\n",
    "}\n",
    "\n",
    "processed_datasets = {}\n",
    "for name, data in datasets.items():\n",
    "    if isinstance(data, tuple):  # For synthetic dataset\n",
    "        X, y = data\n",
    "    elif name == \"covtype\":\n",
    "        X, y = data[\"data\"][:10000], data[\"target\"][:10000]  # Use a subset for speed\n",
    "    else:\n",
    "        X, y = data.data, data.target\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=8080\n",
    "    )\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    test_ds = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=2**14, shuffle=True, num_workers=8, persistent_workers=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=2**14, num_workers=8, persistent_workers=True\n",
    "    )\n",
    "    processed_datasets[name] = {\n",
    "        \"input_size\": X.shape[1],\n",
    "        \"output_size\": len(np.unique(y)),\n",
    "        \"train_loader\": train_loader,\n",
    "        \"val_loader\": test_loader,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956783a5",
   "metadata": {},
   "source": [
    "## 2. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define architectures and their parameters\n",
    "architectures = [\"feedforward\", \"heads\"]\n",
    "network_types = [\"classical\", \"genetic\"]\n",
    "# For feedforward: depth, for heads: n_heads\n",
    "architecture_params = {\n",
    "    \"feedforward\": [2, 4],  # depths\n",
    "    \"heads\": [1, 2],  # n_heads\n",
    "}\n",
    "max_epochs = 256\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc291c0f",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d1a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train networks for each dataset, architecture, network type, and parameter\n",
    "total_combinations = (\n",
    "    len(processed_datasets)\n",
    "    * len(architectures)\n",
    "    * len(network_types)\n",
    "    * len(architecture_params[\"feedforward\"])\n",
    ")\n",
    "pbar = tqdm(total=total_combinations, desc=\"Training combinations\")\n",
    "\n",
    "for dataset_name, data in processed_datasets.items():\n",
    "    input_size = data[\"input_size\"]\n",
    "    output_size = data[\"output_size\"]\n",
    "    train_loader = data[\"train_loader\"]\n",
    "    val_loader = data[\"val_loader\"]\n",
    "\n",
    "    for arch in architectures:\n",
    "        params = architecture_params[arch]\n",
    "        for net_type in network_types:\n",
    "            for param in params:\n",
    "                # Create the appropriate network\n",
    "                if arch == \"feedforward\" and net_type == \"classical\":\n",
    "                    model = create_feedforward_classical_network(\n",
    "                        input_size, param, output_size\n",
    "                    )\n",
    "                elif arch == \"heads\" and net_type == \"classical\":\n",
    "                    model = create_heads_classical_network(\n",
    "                        input_size, param, output_size\n",
    "                    )\n",
    "                elif arch == \"feedforward\" and net_type == \"genetic\":\n",
    "                    model = create_feedforward_genetic_network(\n",
    "                        input_size, param, output_size\n",
    "                    )\n",
    "                elif arch == \"heads\" and net_type == \"genetic\":\n",
    "                    model = create_heads_genetic_network(input_size, param, output_size)\n",
    "                else:\n",
    "                    raise ValueError(\"Unknown architecture or network type\")\n",
    "\n",
    "                # Train and evaluate\n",
    "                metrics = train_and_evaluate(\n",
    "                    model, train_loader, val_loader, max_epochs=max_epochs\n",
    "                )\n",
    "                results[f\"{dataset_name}_{arch}_{net_type}_{param}\"] = metrics\n",
    "                pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2797125",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd13005",
   "metadata": {},
   "source": [
    "### 4.1. Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051aa4eb",
   "metadata": {},
   "source": [
    "#### 4.1.1. Plotting Balanced Accuracy Over Epochs for All Models on All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f94d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_list = list(processed_datasets.keys())\n",
    "\n",
    "# Define all architecture combinations for plotting\n",
    "architecture_combinations = []\n",
    "for arch in architectures:\n",
    "    for net_type in network_types:\n",
    "        for param in architecture_params[arch]:\n",
    "            architecture_combinations.append(f\"{arch}_{net_type}\")\n",
    "\n",
    "# Plot balanced accuracy comparison for each dataset\n",
    "for dataset in datasets_list:\n",
    "    # Plot for feedforward architectures\n",
    "    feedforward_archs = [f\"feedforward_{net_type}\" for net_type in network_types]\n",
    "    fig_ff = plot_architecture_comparison(\n",
    "        results, dataset, feedforward_archs, architecture_params[\"feedforward\"]\n",
    "    )\n",
    "    plt.savefig(f\"artefacts/feedforward_comparison_{dataset}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot for heads architectures\n",
    "    heads_archs = [f\"heads_{net_type}\" for net_type in network_types]\n",
    "    fig_heads = plot_architecture_comparison(\n",
    "        results, dataset, heads_archs, architecture_params[\"heads\"]\n",
    "    )\n",
    "    plt.savefig(f\"artefacts/heads_comparison_{dataset}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0369a",
   "metadata": {},
   "source": [
    "#### 4.1.2. Plotting Balanced Accuracy vs Number of Parameters for All Models on All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets_list:\n",
    "    for arch in [\"feedforward\", \"heads\"]:\n",
    "        plot_bal_acc_vs_params(\n",
    "            results,\n",
    "            dataset,\n",
    "            arch,\n",
    "            save_path=f\"artefacts/bal_acc_vs_params_{dataset}_{arch}.png\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92983f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
